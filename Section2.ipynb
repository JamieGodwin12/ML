import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from warnings import filterwarnings
filterwarnings('ignore')
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.neural_network import MLPClassifier
from sklearn import metrics
from sklearn.model_selection import KFold, cross_val_score

def importData():
    #imports dataset using read function 
    df = pd.read_excel('clinical_dataset.xlsx', engine='openpyxl')
    #status list
    data = df.drop(['Status'], axis=1)
    print("Dataset= \n{0}".format(df))
    #describe Age
    print ('\n Age \n', df['Age'].describe())
    #describe BMI
    print ('\n BMI \n', df['BMI'].describe())
    #describe Glucose
    print ('\n Glucose \n', df['Glucose'].describe())
    #describe Insulin
    print ('\n Insulin \n', df['Insulin'].describe())
    #describe HOMA
    print ('\n HOMA \n', df['HOMA'].describe())
    #describe Leptin
    print ('\n Leptin \n', df['Leptin'].describe())
    #describe Adiponectin
    print ('\n Adiponectin \n', df['Adiponectin'].describe())
    #describe Resistin
    print ('\n Resistin \n', df['Resistin'].describe())
    #describe MCP.1
    print ('\n MCP.1 \n', df['MCP.1'].describe())
    #describe Status
    print ('\n Status \n', df['Status'].describe())
    return df, data
 
def preProcessingData():
    #Pass the loaded df and data
    [df, data] = importData()
    #size and features
    #Rows
    rowData = np.shape(df)[0]
    #Columns
    ColumnData = np.shape(df)[1]  
    print("\nThe size of the dataset = %d Ã— %d\nThe number of features = %d\n"
          % (rowData, ColumnData , ColumnData))
    #finds missing values
    findMissingV(df)

    #finds categorical variables
    listCategories = list(df['Status'].value_counts().index)
    print("\nThe categorical variables =", listCategories)
    statusDummy = pd.get_dummies(df['Status'], drop_first=False, prefix='Status')
    print(statusDummy)

    #normalise before training and testing of any model
    #feature scaling
    print("\nMin Max normalization method =\n", minMaxNorm(data)) 
    
    # Plot the box and density plots
    Plots(df)
    return

def statistics(dataset, name):
    #gets std from statistics and prints it   
    stdV = ("%.2f" % np.std(dataset))  
    print("The standard deviation value of %s = %s" % (name, stdV))   
    return

def findMissingV(dataset):
    #find the location of missing vaules 
    missingValue = dataset.isnull().any()
    print("\nThe missing value status are =\n", missingValue)
    return

def minMaxNorm(dataset):
    #feature scaling
    normalData = (dataset-np.min(dataset))/(np.max(dataset)- np.min(dataset))
    return normalData

def Plots(df):
    #status and age boxplot
    df.boxplot('Age', 'Status',meanline=True, showmeans=True,
               #sets mean value point
               meanprops={'marker': 'D'},
               #Set median line
               medianprops={'marker': 'v'})
    titleBoxplot = 'Boxplot of cancerous and healthy'
    plt.title( titleBoxplot )
    plt.suptitle('') 
    plt.xlabel("Status")
    plt.ylabel('Age')
    plt.show()
    # Plot the density plot of BMI
    #healthy BMI status = healthy for BMI
    BMIhealthy = df[df['Status'] == 'healthy']['BMI']
    #cancerous status = cancerous for BMI
    BMIcancerous = df[df['Status'] == 'cancerous']['BMI'] 
    #plots healthy and cancerous
    sns.kdeplot(BMIcancerous, label="Cancerous status", color="aqua")
    sns.kdeplot(BMIhealthy, label="Healthy status", color="black")       
    plt.title('Density plot of BMI')
    plt.xlabel('BMI')
    plt.ylabel('Density')
    plt.show()
    return

def processingData():
    #gets the dataset 
    [df, data] = importData()
    #list of status 
    statusData = df['Status'] 
    #normalised data
    normalData = minMaxNorm(data)
    #healthy = 0 cancerous = 1
    statusData = statusData.apply(lambda x: 1 if 'cancerous' in x else 0)
    #shuffels df and splits training and testing sets
    xTrain, xTest, yTrain, yTest = train_test_split(normalData, statusData, test_size=0.1)
    return xTrain, xTest, yTrain, yTest

def ANNmodel(xTrain, xTest, yTrain, yTest, epochs=200):
    global accuracy
    #stores accuarcy vaules
    accuracyArray = []
    for epoch in range(1, epochs, 20):
        ann = MLPClassifier(shuffle=True, hidden_layer_sizes=[500, 500], activation='logistic',
        alpha=0.1, random_state=1, max_iter=epoch)
        #fits ann with traing data x and target y 
        ann.fit(xTrain, yTrain) 
        #avrage accuaracy value  
        accuracy = ann.score(xTest, yTest)
        #accuarcy value added arracy 
        accuracyArray.append(accuracy)
    print('ANN Accuracy= %.2f%%' % (accuracy * 100))
    #makes the plot
    plt.plot(range(1, epochs, 20), accuracyArray, color='c', label='Accuracy')
    plt.xlabel('Epochs'), plt.ylabel('Accuracy'), plt.title("Accuracy compared to Epochs")
    plt.legend()
    plt.show()  
    return

def forestModel(xTrain, xTest, yTrain, yTest, treeNumber=1000, min_sam=5):
    clf = RandomForestClassifier(n_estimators=treeNumber, max_depth=None,
    min_samples_split=min_sam, bootstrap=True, oob_score=True)
    #cross validation
    #classifier fit with traning data 
    clf.fit(xTrain, yTrain)
    #trained classifier used to perdict labels
    yPredict = clf.predict(xTest)
    #accracy updated
    accuracyTest = "%.2f%%" % ((metrics.accuracy_score(yTest, yPredict)) * 100)
    return accuracyTest

def dataProcessing2():
    #gets the dataset 
    [df, data] = importData() 
    #list of status 
    statusData = df['Status']
    #healthy = 0 cancerous = 1
    statusData = statusData.apply(lambda x: 1 if 'cancerous' in x else 0)
    #data normalisation
    normalData = minMaxNorm(data) 
    return normalData, statusData

def ANNvalidation(normalData, statusData, neurons, folds):
    #stores vaules for models 
    crossValidationScore = [] 
    Kfolds = KFold(shuffle=True, n_splits=folds)
    #gets the diffrent neuron numbers from ANNmodel
    for neuron in neurons: 
        ann = MLPClassifier(shuffle=True, hidden_layer_sizes=[neuron, neuron], activation='logistic',
        alpha=0.1, random_state=0)
        #cross validation 
        score = cross_val_score(ann, normalData, statusData, cv=Kfolds)
        crossValidationScore.append(score.mean())
        #print accuracy 
        print("ANN neurons = %d accuracy = %0.2f" % (neuron, score.mean()))
    return

def forestsValidation(normalData, statusData, trees, folds, min_samples):
    #stores vaules for models 
    crossValidationScore = []
    Kfolds = KFold(shuffle=True, n_splits=folds)
    #gets the diffrent tree numbers from forestModel
    for tree in trees:
        forestModel = RandomForestClassifier(n_estimators=tree, min_samples_split=min_samples,
        bootstrap=True, oob_score=True)
        #cross validation 
        score = cross_val_score(forestModel, normalData, statusData, cv=Kfolds)
        crossValidationScore.append(score.mean())
        #print accuracy 
        print("Forests trees = %d accuracy = %0.2f" % (tree, score.mean()))
    return
   
def main():
    preProcessingData() 
    tree_number = [10, 50, 100, 1000,5000]
    min_samples = [5, 50]
    xTrain, xTest, yTrain, yTest = processingData()
    ANNmodel(xTrain, xTest, yTrain, yTest)
    accuracySample1 = forestModel(xTrain, xTest, yTrain, yTest, 1000, 50)
    accuracySample2 = forestModel(xTrain, xTest, yTrain, yTest, 1000, 5)
    print('Min Samples=50 Forests Model Accuracy =', accuracySample1)
    print('Min Samples=05 Forests Model Accuracy =', accuracySample2)   
    normalData, statusData = dataProcessing2()
    #hidden layers and neuron sizes 
    hiddenNeurons = [50, 500, 1000]
    #forest trees number
    treesNumber = [20, 500, 10000]
    # Set parameters ANN/Forests for evaluation
    ANNvalidation(normalData, statusData, hiddenNeurons, folds=10)  
    forestsValidation(normalData, statusData, treesNumber, folds=10, min_samples=5)
    return
if __name__ == '__main__':   
    main()

    

